{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment 4</h1>\n",
    "<h2>Pima Indians Diabetes</h2>\n",
    "<br>\n",
    "<p>I am interested in this dataset because my father has suffered with Diabetes since he was a child.</p>\n",
    "<p>https://www.kaggle.com/uciml/pima-indians-diabetes-database</p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Clustering, Bisecting k-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalization(X):\n",
    "    # compute mean and stdev over axis 0, the feature vector (down the column)\n",
    "    mean = np.mean(X,0)\n",
    "    stddev = np.std(X,0)\n",
    "    \n",
    "    # elementwise difference\n",
    "    diff = np.subtract(X,mean)\n",
    "    \n",
    "    # elementwise division\n",
    "    normalized = np.divide(diff,stddev)\n",
    "    \n",
    "    # for testing\n",
    "    # for each feature, stddev should be 1 and mean should be 0\n",
    "    #print(\"stddev of normalized\", np.std(normalized,0))    \n",
    "    #print(\"mean of normalized\", np.mean(normalized,0))    \n",
    "    \n",
    "    return normalized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_2_clusters(X, max_iter, random_state = 42):\n",
    "    km = KMeans(n_clusters=2, max_iter = max_iter, random_state=random_state)\n",
    "    km.fit(X)\n",
    "    return km.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BKMEANS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkmeans(X, k, max_iter, random_state = 42):\n",
    "    # K should be greater than 1, otherwise it can be considered already a cluster\n",
    "    assert k>1\n",
    "    \n",
    "    # Step 1, initialize by dividing in to two clusters\n",
    "    clusters = kmeans_2_clusters(X, max_iter)\n",
    "    cluster_counter = 2\n",
    "    \n",
    "    # Step 2, Iterate until reached num of clusters desired\n",
    "    while cluster_counter < k:\n",
    "        # Get largest cluster\n",
    "        cluster_ids, cluster_counts = np.unique(clusters, return_counts = True)\n",
    "        largest_cluster_index = np.argmax(cluster_counts)\n",
    "        \n",
    "        # This is actually unnecessary because the id always matches the index\n",
    "        largest_cluster_id = cluster_ids[largest_cluster_index]\n",
    "        \n",
    "        # Get indices of elements in the largest cluster \n",
    "        indices = np.nonzero(clusters == largest_cluster_id)[0]\n",
    "        \n",
    "        # Get values of subcluster for use in Kmeans\n",
    "        values_largest_cluster = X[indices]\n",
    "        \n",
    "        # Split subcluster into two smaller clusters\n",
    "        subcluster_labels = kmeans_2_clusters(values_largest_cluster, max_iter)\n",
    "        \n",
    "        # Get indices of new subcluster that is mapped to 0 (arbitrary, can choose 0 or 1)\n",
    "        subcluster_label_indices = np.nonzero(subcluster_labels == 0)[0]\n",
    "\n",
    "        # Map indices of new subcluster back to the main cluster array\n",
    "        original_indices = indices[subcluster_label_indices]\n",
    "        \n",
    "        # Update main cluster array with new subcluster assignments\n",
    "        clusters[original_indices] = cluster_counter\n",
    "        cluster_counter += 1\n",
    "    \n",
    "    return clusters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex1():\n",
    "    # load data\n",
    "    data = np.loadtxt('./diabetes.csv',delimiter=',',skiprows=1)\n",
    "    X = data[:, 0:-1]\n",
    "    #y = data[:, -1]\n",
    "\n",
    "    # Normalize Data\n",
    "    Xn = feature_normalization(X)\n",
    "    \n",
    "    # Get Clusters\n",
    "    clusters = bkmeans(Xn, 10, 10)\n",
    "    \n",
    "    print(\"A4, EX1\\nclusters.shape\",clusters.shape,\"\\nclusters\",clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ex1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Non-linear Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The algorithm can be implemented with gradient descent using the following steps:</p>\n",
    "<ol><li>Start with a random two-dimensional layout Y of points (Y is a n × 2 matrix).</li>\n",
    "    <li>Compute the stress E of Y . See slide 47 of Lecture 12 for the formula.</li>\n",
    "    <li>If E < ε, or if the maximum number of iterations iter has been reached, stop.</li>\n",
    "    <li>For each yi of Y , find the next vector yi(t + 1) based on the current yi(t). See slide 48 of lecture 12</li><li>Go to Step 2.</li></ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(X, Y):\n",
    "    \"\"\" Create distance matrix \n",
    "    Note:\n",
    "        1. Optimization level - highly optimized! I used this during assignment 1. \n",
    "        Algorithm was found https://medium.com/@souravdey/l2-distance-matrix-vectorization-trick-26aa3247ac6c\n",
    "        It is a no loop solution, which means it can handle the matrices in\n",
    "        one line of code rather than having to iterate over the rows of one\n",
    "        matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"get_distance_matrix\")\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    \n",
    "    # perform operation in parts due to tiny numbers causing error with sqrt\n",
    "    eu1 = -2 * np.dot(Y, X.T) + np.sum(X**2, axis=1) + np.sum(Y**2, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # replace tiny numbers with 0\n",
    "    eu1 = np.where(np.absolute(eu1)<1e-10,0,eu1)\n",
    "    \n",
    "    # return sqrt of 'clean' matrix\n",
    "    return np.sqrt(eu1)\n",
    "\n",
    "def get_c(X):\n",
    "    # C is the sum of all elements of the upper triangular distance matrix\n",
    "    return np.sum(np.triu(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A4, EX2\n",
      "get_distance_matrix\n",
      "(5, 3)\n",
      "(5, 3)\n",
      "hd_delta_matrix [[ 0.         63.48228099 35.95830919 59.51470407 34.36568055]\n",
      " [63.48228099  0.         98.27003612  4.         58.14636704]\n",
      " [35.95830919 98.27003612  0.         94.28149341 52.49761899]\n",
      " [59.51470407  4.         94.28149341  0.         54.59853478]\n",
      " [34.36568055 58.14636704 52.49761899 54.59853478  0.        ]]\n",
      "c 555.1150251553903\n",
      "reduced_matrix [[0.95030622 0.29950058]\n",
      " [0.27768875 0.15929752]\n",
      " [0.04230412 0.87012085]\n",
      " [0.23844364 0.06102602]\n",
      " [0.54449739 0.47736873]]\n",
      "i 1\n",
      "get_distance_matrix\n",
      "(5, 2)\n",
      "(5, 2)\n",
      "a -0.0036028569023873044\n",
      "b [[ 0.         62.79520665 34.88589355 58.76395881 33.92260281]\n",
      " [62.79520665  0.         97.52125329  3.89418192 57.73120907]\n",
      " [34.88589355 97.52125329  0.         93.44896404 51.86008287]\n",
      " [58.76395881  3.89418192 93.44896404  0.         54.08180453]\n",
      " [33.92260281 57.73120907 51.86008287 54.08180453  0.        ]]\n",
      "cc [[ 0.         43.61704644 38.56225317 44.680382   15.22666809]\n",
      " [43.61704644  0.         73.58291607  0.42327233 24.1399278 ]\n",
      " [38.56225317 73.58291607  0.         78.4921123  33.46912854]\n",
      " [44.680382    0.42327233 78.4921123   0.         28.21271431]\n",
      " [15.22666809 24.1399278  33.46912854 28.21271431  0.        ]]\n",
      "d [[0.         0.11312107 0.06284444 0.10585907 0.06110914]\n",
      " [0.11312107 0.         0.17567756 0.00701509 0.10399864]\n",
      " [0.06284444 0.17567756 0.         0.16834162 0.09342223]\n",
      " [0.10585907 0.00701509 0.16834162 0.         0.0974245 ]\n",
      " [0.06110914 0.10399864 0.09342223 0.0974245  0.        ]]\n",
      "e [[0.         0.11312107 0.06284444 0.10585907 0.06110914]\n",
      " [0.11312107 0.         0.17567756 0.00701509 0.10399864]\n",
      " [0.06284444 0.17567756 0.         0.16834162 0.09342223]\n",
      " [0.10585907 0.00701509 0.16834162 0.         0.0974245 ]\n",
      " [0.06110914 0.10399864 0.09342223 0.0974245  0.        ]]\n",
      "f [[-0.00677103 -0.00213397]\n",
      " [-0.00197856 -0.00113501]\n",
      " [-0.00030142 -0.0061997 ]\n",
      " [-0.00169894 -0.00043482]\n",
      " [-0.0038796  -0.0034013 ]]\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "def sammon(hd_matrix, max_iter=2, eps=.3, alpha=0):\n",
    "    hd_delta_matrix = get_distance_matrix(hd_matrix, hd_matrix)\n",
    "    print(\"hd_delta_matrix\",hd_delta_matrix)\n",
    "\n",
    "    c = get_c(hd_delta_matrix)\n",
    "    print(\"c\",c)\n",
    "    \n",
    "    reduced_matrix = np.random.rand(len(hd_matrix),2)\n",
    "    print(\"reduced_matrix\",reduced_matrix)\n",
    "    \n",
    "    for curr_iter in range(1,max_iter):\n",
    "        print(\"i\", curr_iter)\n",
    "\n",
    "        yitp1 = gradient(reduced_matrix, hd_delta_matrix, eps, c)\n",
    "        \n",
    "        #print(\"yitp1\",yitp1)\n",
    "        #print(\"yitp1-reduced_matrix\",yitp1-reduced_matrix)\n",
    "        \n",
    "        #reduced_matrix = yitp1\n",
    "        \n",
    "    pass\n",
    "\n",
    "def gradient(reduced_matrix, hd_delta_matrix, eps, c ):\n",
    "    reduced_delta_matrix = get_distance_matrix(reduced_matrix, reduced_matrix)\n",
    "    a = reduced_matrix - eps\n",
    "    b = pd1(reduced_matrix, hd_delta_matrix, reduced_delta_matrix, c)\n",
    "    pass\n",
    "    \n",
    "def pd1(reduced_matrix, hd_delta_matrix, reduced_delta_matrix, c):\n",
    "    a = (-2/c)\n",
    "    print(\"a\", a)\n",
    "    \n",
    "    b = hd_delta_matrix - reduced_delta_matrix\n",
    "    print(\"b\", b)\n",
    "    \n",
    "    cc = hd_delta_matrix * reduced_delta_matrix\n",
    "    print(\"cc\", cc)\n",
    "    \n",
    "    # We should not be dividing by zero, however, this causes a runtime warning only \n",
    "    # on Jupyter and only affects the elements along the diagonal (or maybe other datapoints with 0 distance)\n",
    "    # Therefore, this operation does not block an otherwise efficient way to compute this as a matrix operation\n",
    "    # We simply perform the division, ignore the warning in place, and then fix the divide by zero cells, changing\n",
    "    # them from nan back to 0. Then we can sum over the matrix later using numpy and avoid for loops\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        try:\n",
    "            d = b / c\n",
    "            print(\"d\", d)\n",
    "        except Warning as e:\n",
    "            print('error found:', e)\n",
    "    \n",
    "    e = np.nan_to_num(d)\n",
    "    print(\"e\",e)\n",
    "    \n",
    "    f = (-2/c) * np.sum(e) * reduced_matrix\n",
    "    print(\"f\",f)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def pd2(reduced_matrix, hd_delta_matrix, reduced_delta_matrix, c):\n",
    "    return (-2/c) * np.sum()\n",
    "\n",
    "def ex2():\n",
    "    print(\"A4, EX2\")\n",
    "    \n",
    "    # load data\n",
    "    data = np.loadtxt('./diabetes.csv',delimiter=',',skiprows=1)\n",
    "    X = data[:, 0:-1]\n",
    "    X = data[:5,0:3]\n",
    "    #y = data[:, -1]\n",
    "\n",
    "    # Normalize Data\n",
    "    #Xn = feature_normalization(X)\n",
    "    Xn = X\n",
    "    \n",
    "    # Get Clusters\n",
    "    sammon(Xn)\n",
    "    \n",
    "    \n",
    "ex2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A4, EX2\n",
      "get_distance_matrix\n",
      "(5, 3)\n",
      "(5, 3)\n",
      "hd_delta_matrix [[ 0.         63.48228099 35.95830919 59.51470407 34.36568055]\n",
      " [63.48228099  0.         98.27003612  4.         58.14636704]\n",
      " [35.95830919 98.27003612  0.         94.28149341 52.49761899]\n",
      " [59.51470407  4.         94.28149341  0.         54.59853478]\n",
      " [34.36568055 58.14636704 52.49761899 54.59853478  0.        ]]\n",
      "c 555.1150251553903\n",
      "reduced_matrix [[0.45532847 0.19196157]\n",
      " [0.53508728 0.57765903]\n",
      " [0.05354567 0.08765681]\n",
      " [0.82661492 0.48836397]\n",
      " [0.50378633 0.44228082]]\n",
      "i 1\n",
      "get_distance_matrix\n",
      "(5, 2)\n",
      "(5, 2)\n",
      "a -0.0036028569023873044\n",
      "b [[ 0.         63.08842314 35.54320812 59.03961669 34.1107141 ]\n",
      " [63.08842314  0.         97.58302484  3.69510334 58.00741737]\n",
      " [35.54320812 97.58302484  0.         93.41074528 51.92449175]\n",
      " [59.03961669  3.69510334 93.41074528  0.         54.27243363]\n",
      " [34.1107141  58.00741737 51.92449175 54.27243363  0.        ]]\n",
      "cc [[ 0.         25.00299455 14.9263327  28.27468472  8.76209579]\n",
      " [25.00299455  0.         67.51262362  1.21958665  8.0794183 ]\n",
      " [14.9263327  67.51262362  0.         82.09543381 30.08781574]\n",
      " [28.27468472  1.21958665 82.09543381  0.         17.80464501]\n",
      " [ 8.76209579  8.0794183  30.08781574 17.80464501  0.        ]]\n",
      "d [[0.         0.11364928 0.06402855 0.10635565 0.06144801]\n",
      " [0.11364928 0.         0.17578884 0.00665646 0.10449621]\n",
      " [0.06402855 0.17578884 0.         0.16827277 0.09353826]\n",
      " [0.10635565 0.00665646 0.16827277 0.         0.09776791]\n",
      " [0.06144801 0.10449621 0.09353826 0.09776791 0.        ]]\n",
      "e [[0.         0.11364928 0.06402855 0.10635565 0.06144801]\n",
      " [0.11364928 0.         0.17578884 0.00665646 0.10449621]\n",
      " [0.06402855 0.17578884 0.         0.16827277 0.09353826]\n",
      " [0.10635565 0.00665646 0.16827277 0.         0.09776791]\n",
      " [0.06144801 0.10449621 0.09353826 0.09776791 0.        ]]\n",
      "f [[-0.00325473 -0.00137216]\n",
      " [-0.00382485 -0.00412915]\n",
      " [-0.00038275 -0.00062658]\n",
      " [-0.00590871 -0.00349087]\n",
      " [-0.00360111 -0.00316146]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
